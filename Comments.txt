### AFTER FINISHED: CHECK ALL CATEGORIES HAVE AT LEAST ONE SELECTION ###

### STATS ###

Correct Overall: 40.00%
MCQ: 53.33%
Programming: 22.50%
Programming (nonzero in 10 attempts): 50.00%
Image Questions (novice): 22.35%
Image Questions (informed): 29.33%

###

No nonsense is generated, all solutions look convincing.

Generated answers contradict each other, e.g. (a) was stated to be the correct answer at the start, then (b) was stated to be correct at the end.

Not a lot of variety was shown in some generated answers, even wrong ones. (Temperature = 0.75)

The language is not specified, so some Python/Java solutions are produced instead of C++.

Some OpenGL specifics could not be generated consistently (only sometimes), such as glBegin() and glEnd().

Minor errors are found consistently which stop programs from working (only slight tweaks are needed, e.g. function calls: pq.cross(pr) instead of cross(pq, pr) [2022a13])

2022a15: Small details such as vertex order (anticlockwise) could not be captured.

2022a17: Small details such as operand order ("Vector3 * int" instead of "int * Vector") could not be captured. Concepts are "well understood", but implementations are lacking slightly in terms of specific requirements.

The model performs poorly on Color questions.

The model chooses the correct option but the wrong corresponding letter.

2022b10: The correct answer is generated sometimes, but they are always flukes, and there were always some calculation errors in the steps.

â˜… Results could vary between different preprocessing techniques and methods, this research only outlines what a typical student would do and achieve if they were to use GPT to "aid" their question solving.

2022b13 & 2022b14: The representation of image matrices using \n and \t may be confusing for the model. Some values are made up.

2022b15b: Rotation was still towards the other direction, despite before and after vertices being stated. Stating vertices did not change the proportion of right answers generated.

2022b17a: Several instances of the same incorrect answer were generated.

2022b17 (RGB Cube) & 2022b18 (drawTorus()) & 2022b19 (Mountain texture mapping): 0/40 generations were successful.

2022b20: Novice 0/10 vs Informed 9/10 because of vital information captured in the image description.

2022b22: The model keeps generating the solution for p0, p1, r0, r1.

2023a05: When applying transformation matrices, the order of the matrices was not taken into account (although it was considered in the explanation).

Minor errors occur (not limited to) when generated code does not follow specified rules (e.g. operation order).

2023a21a: For some generations, the ratios for corners do not get paired with the correct corners.

2023a21b: normalise() vs normalize();

Use a paired t-test to test whether the knowledge level of the student makes a significant difference in the performance. Also depends on how much information the image holds that is relevant and crucial for solving the question.

2023a22a: Need to know where to extract the relevant code snippets.

2023a22: Generated code usually contains functions, which are not allowed in this question.

